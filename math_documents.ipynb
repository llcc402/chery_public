{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from utilities import softplus, get_max_with_structure, get_cross_logits_y\n",
    "from models import HMCModel\n",
    "from utils import datasets\n",
    "from utils.parser import * \n",
    "import networkx as nx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1392.6467, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_name = 'seq_FUN'\n",
    "train, valid, test = initialize_dataset(dataset_name, datasets)\n",
    "\n",
    "train.Y = tf.convert_to_tensor(train.Y, tf.float32)\n",
    "valid.Y = tf.convert_to_tensor(valid.Y, tf.float32)\n",
    "test.Y = tf.convert_to_tensor(test.Y, tf.float32)\n",
    "\n",
    "def get_structure_from_adajancency(adajancency):\n",
    "    structure = np.zeros(adajancency.shape)\n",
    "    g = nx.DiGraph(adajancency) # train.A is the matrix where the direct connections are stored \n",
    "    for i in range(len(adajancency)):\n",
    "        ancestors = list(nx.descendants(g, i)) #here we need to use the function nx.descendants() because in the directed graph the edges have source from the descendant and point towards the ancestor \n",
    "        if ancestors:\n",
    "            structure[i, ancestors] = 1\n",
    "    return structure \n",
    "\n",
    "def mymax1(prob, structure):\n",
    "    structure = (structure + np.eye(structure.shape[0])).astype(np.float32)\n",
    "    structure = structure[np.newaxis,:,:]\n",
    "    prob = prob[:,:,tf.newaxis]\n",
    "    prob1 = tf.reduce_max(prob * structure, axis=1)\n",
    "    return prob1\n",
    "\n",
    "def mylog(x):\n",
    "    x = tf.where(x < 1e-30, 1e-30, x)\n",
    "    return tf.math.log(x)\n",
    "\n",
    "def loss_fn(y_true, y_logits, structure):\n",
    "    idx = tf.cast(tf.reduce_sum(y_true, axis=0) != y_true.shape[0], tf.float32) # remove root nodes\n",
    "    prob = tf.nn.sigmoid(y_logits)\n",
    "    part1 = - y_true * mylog(mymax1(prob * y_true, structure))\n",
    "    part2 = - (1-y_true) * mylog(1 - mymax1(prob, structure))\n",
    "    loss = part1 + part2\n",
    "    loss = tf.reduce_mean(loss*idx)\n",
    "    return loss \n",
    "\n",
    "def loss_fn_funny(y_true, y_logits, structure):\n",
    "    idx = tf.squeeze(tf.where(tf.reduce_sum(y_true, axis=0) != y_true.shape[0])) # remove root nodes\n",
    "    prob = tf.nn.sigmoid(y_logits)\n",
    "    c_out = mymax1(prob, structure)\n",
    "    t_out = y_true * prob\n",
    "    t_out = mymax1(t_out, structure)\n",
    "    t_out = (1-y_true) * c_out + y_true * t_out\n",
    "    y_true1 = tf.gather(y_true, idx, axis=1)\n",
    "    t_out1 = tf.gather(t_out, idx, axis=1)\n",
    "    loss = tf.losses.BinaryCrossentropy(from_logits=False)(\n",
    "        y_true1, t_out1\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "from utilities import softplus\n",
    "\n",
    "def get_z(y_true, logits):\n",
    "    return tf.where(y_true == 1, logits, -np.inf)\n",
    "def mymax2(logits, structure):\n",
    "    structure = (structure + np.eye(structure.shape[0])).astype(np.float32)\n",
    "    structure = np.where(structure == 1, structure, -np.inf)\n",
    "    structure = np.where(structure==1, 0, structure)\n",
    "    structure = structure[np.newaxis,:,:]\n",
    "    logits = logits[:,:,tf.newaxis]\n",
    "    outputs = tf.reduce_max(structure + logits, axis=1)\n",
    "    return outputs\n",
    "def loss_fn_logits(y_true, y_logits, structure):\n",
    "    z = get_z(y_true, y_logits)\n",
    "    max_z = mymax2(z, structure)\n",
    "    max_z = tf.where(tf.math.is_inf(max_z), np.inf, max_z)\n",
    "    max_x = mymax2(y_logits, structure)\n",
    "    outputs = y_true * softplus(max_z) + (1-y_true)*max_x + (1-y_true)*softplus(max_x)\n",
    "    return tf.reduce_mean(outputs)\n",
    "\n",
    "structure = get_structure_from_adajancency(train.A)\n",
    "model = HMCModel(structure, 500, [2000,2000], 0.7)\n",
    "logits= model(train.X)\n",
    "print(loss_fn_logits(train.Y, logits, structure))\n",
    "print(loss_fn(train.Y, logits, structure))\n",
    "print(loss_fn_funny(train.Y, logits, structure))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary cross entropy from logits is realized by \n",
    "$$\n",
    "\\begin{aligned}\n",
    "L &= -y * \\log\\left(\\frac{1}{1+e^{-x}}\\right) - (1-y) * \\log\\left(1-\\frac{1}{1+e^{-x}}\\right) \\\\\n",
    "  &= y * \\log (1+e^{-x}) - (1-y) \\log e^{-x} + (1-y) \\log (1+e^{-x}) \\\\\n",
    "  &= \\log (1+e^{-x}) + (1-y)x\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "official = 1080.99609375\n",
      "my loss = 1080.99609375\n"
     ]
    }
   ],
   "source": [
    "y = tf.convert_to_tensor([[1.0, 0.0], [0.0, 0.0]], tf.float32)\n",
    "logits = tf.random.uniform([2,2], -100000, 100000, tf.float32)\n",
    "f = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "print(\"official = {}\".format(f(y, logits)))\n",
    "\n",
    "def my_loss(y_true, logits):\n",
    "    return tf.reduce_mean(softplus(logits) + (1-y) * logits)\n",
    "\n",
    "print(\"my loss = {}\".format(my_loss(y_true=y, logits=logits)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The special loss function developed by C-HMC is \n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_i &= -y_i \\log \\left(\\max_{j\\leq i}\\frac{y_j}{1+e^{-x_j}}\\right) - (1-y_i) \\log \\left(1 - \\max_{j\\leq i}\\frac{1}{1+e^{-x_j}}\\right) \\\\\n",
    "&= -y_i \\log \\left(\\frac{1}{1+e^{-\\max_{j\\leq i}z_j}}\\right) - (1-y_i) \\log \\left(1 - \\frac{1}{1+e^{-\\max_{j\\leq i}x_j}}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "where \n",
    "$$\n",
    "z_j = \\begin{cases} x_j, &y_i=1 \\\\ -\\infty &y_i=0\\end{cases}\n",
    "$$\n",
    "Then \n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_i &= y_i \\log (1+e^{-\\max_{j\\leq i}z_j}) - (1-y_i) \\log e^{-\\max_{j\\leq i}x_j} + (1-y_i) \\log(1+e^{-\\max_{j\\leq i}x_j}) \\\\\n",
    "&= y_i \\log (1+e^{-\\max_{j\\leq i}z_j}) + (1-y_i) \\max_{j\\leq i}x_j + (1-y_i) \\log(1+e^{-\\max_{j\\leq i}x_j})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mylog(x):\n",
    "    x = tf.where(x < 1e-10, 1e-10, x)\n",
    "    return tf.math.log(x)\n",
    "a1 = -(1-train.Y) * mylog(1 - mymax1(tf.nn.sigmoid(logits), structure))\n",
    "a2 = (1-train.Y) * mymax2(logits, structure) + (1-train.Y) * softplus(mymax2(logits, structure))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1701, 500), dtype=float32, numpy=\n",
       "array([[23.025852,  0.      , 23.025852, ..., -0.      , -0.      ,\n",
       "        -0.      ],\n",
       "       [23.025852,  0.      ,  0.      , ..., -0.      , -0.      ,\n",
       "        -0.      ],\n",
       "       [23.025852, 23.025852, 23.025852, ..., -0.      , -0.      ,\n",
       "        -0.      ],\n",
       "       ...,\n",
       "       [23.025852, 23.025852, 23.025852, ..., -0.      , -0.      ,\n",
       "        -0.      ],\n",
       "       [23.025852, 23.025852, 23.025852, ..., -0.      , -0.      ,\n",
       "        -0.      ],\n",
       "       [23.025852, 23.025852, 23.025852, ..., -0.      , -0.      ,\n",
       "        -0.      ]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1701, 500), dtype=float32, numpy=\n",
       "array([[ 6857.3125 ,     0.     ,  4710.999  , ...,     0.     ,\n",
       "            0.     ,     0.     ],\n",
       "       [11204.918  ,     0.     ,     0.     , ...,     0.     ,\n",
       "            0.     ,     0.     ],\n",
       "       [ 4930.644  ,  2479.6807 ,  3386.169  , ...,     0.     ,\n",
       "            0.     ,     0.     ],\n",
       "       ...,\n",
       "       [ 3874.703  ,  1948.2192 ,  2660.057  , ...,     0.     ,\n",
       "            0.     ,     0.     ],\n",
       "       [ 1734.8218 ,   872.83765,  1190.6101 , ...,     0.     ,\n",
       "            0.     ,     0.     ],\n",
       "       [ 5344.9736 ,  2688.7131 ,  3674.2456 , ...,     0.     ,\n",
       "            0.     ,     0.     ]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1701, 500), dtype=float32, numpy=\n",
       "array([[ 6857.3125 ,  3451.138  ,  4710.999  , ..., -2666.988  ,\n",
       "        -3162.3025 , -1660.6555 ],\n",
       "       [11204.918  ,  5631.376  ,  7698.882  , ..., -4354.895  ,\n",
       "        -5151.0503 , -2719.425  ],\n",
       "       [ 4930.644  ,  2479.6807 ,  3386.169  , ..., -1917.3706 ,\n",
       "        -2271.438  , -1196.0271 ],\n",
       "       ...,\n",
       "       [ 3874.703  ,  1948.2192 ,  2660.057  , ..., -1505.5505 ,\n",
       "        -1781.5996 ,  -941.77686],\n",
       "       [ 1734.8218 ,   872.83765,  1190.6101 , ...,  -674.4989 ,\n",
       "         -799.27716,  -422.12793],\n",
       "       [ 5344.9736 ,  2688.7131 ,  3674.2456 , ..., -2078.768  ,\n",
       "        -2465.588  , -1297.5853 ]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymax2(logits, structure)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d1df8a9c631c41e95662a04b9faaa5fcedaf5ec92d88d24f4a9901426a87932"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
