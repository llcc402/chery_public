{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from utilities import softplus, get_max_with_structure, get_cross_logits_y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary cross entropy from logits is realized by \n",
    "$$\n",
    "\\begin{aligned}\n",
    "L &= -y * \\log\\left(\\frac{1}{1+e^{-x}}\\right) - (1-y) * \\log\\left(1-\\frac{1}{1+e^{-x}}\\right) \\\\\n",
    "  &= y * \\log (1+e^{-x}) - (1-y) \\log e^{-x} + (1-y) \\log (1+e^{-x}) \\\\\n",
    "  &= \\log (1+e^{-x}) + (1-y)x\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "official = 1080.99609375\n",
      "my loss = 1080.99609375\n"
     ]
    }
   ],
   "source": [
    "y = tf.convert_to_tensor([[1.0, 0.0], [0.0, 0.0]], tf.float32)\n",
    "logits = tf.random.uniform([2,2], -100000, 100000, tf.float32)\n",
    "f = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "print(\"official = {}\".format(f(y, logits)))\n",
    "\n",
    "def my_loss(y_true, logits):\n",
    "    return tf.reduce_mean(softplus(logits) + (1-y) * logits)\n",
    "\n",
    "print(\"my loss = {}\".format(my_loss(y_true=y, logits=logits)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The special loss function developed by C-HMC is \n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_i &= -y_i \\log \\left(\\max_{j\\leq i}\\frac{y_j}{1+e^{-x_j}}\\right) - (1-y_i) \\log \\left(1 - \\max_{j\\leq i}\\frac{1}{1+e^{-x_j}}\\right) \\\\\n",
    "&= -y_i \\log \\left(\\frac{1}{1+e^{-\\max_{j\\leq i}z_j}}\\right) - (1-y_i) \\log \\left(1 - \\frac{1}{1+e^{-\\max_{j\\leq i}x_j}}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "where \n",
    "$$\n",
    "z_j = \\begin{cases} x_j, &y_i=1 \\\\ -\\infty &y_i=0\\end{cases}\n",
    "$$\n",
    "Then \n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_i &= y_i \\log (1+e^{-\\max_{j\\leq i}z_j}) - (1-y_i) \\log e^{-\\max_{j\\leq i}x_j} + (1-y_i) \\log(1+e^{-\\max_{j\\leq i}x_j}) \\\\\n",
    "&= y_i \\log (1+e^{-\\max_{j\\leq i}z_j}) + (1-y_i) \\max_{j\\leq i}x_j + (1-y_i) \\log(1+e^{-\\max_{j\\leq i}x_j})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import datasets\n",
    "from utils.parser import * \n",
    "import networkx as nx \n",
    "\n",
    "dataset_name = 'seq_FUN'\n",
    "train, valid, test = initialize_dataset(dataset_name, datasets)\n",
    "\n",
    "train.Y = tf.convert_to_tensor(train.Y, tf.float32)\n",
    "valid.Y = tf.convert_to_tensor(valid.Y, tf.float32)\n",
    "test.Y = tf.convert_to_tensor(test.Y, tf.float32)\n",
    "\n",
    "def get_structure_from_adajancency(adajancency):\n",
    "    structure = np.zeros(adajancency.shape)\n",
    "    g = nx.DiGraph(adajancency) # train.A is the matrix where the direct connections are stored \n",
    "    for i in range(len(adajancency)):\n",
    "        ancestors = list(nx.descendants(g, i)) #here we need to use the function nx.descendants() because in the directed graph the edges have source from the descendant and point towards the ancestor \n",
    "        if ancestors:\n",
    "            structure[i, ancestors] = 1\n",
    "    return structure \n",
    "\n",
    "structure = get_structure_from_adajancency(train.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0505993>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss_1(y, logits, structure):\n",
    "    # use a modified version\n",
    "    def max_with_structure(prob, structure):\n",
    "        prob = prob.numpy()\n",
    "        structure = (structure + np.eye(structure.shape[0])).astype(np.int16)\n",
    "        prob1 = np.zeros_like(prob)\n",
    "        for i in range(structure.shape[0]):\n",
    "            prob1[:,i] = np.max(prob[:,structure[i]==1],axis=1)\n",
    "        return tf.convert_to_tensor(prob1,tf.float32)\n",
    "\n",
    "    prob = tf.nn.sigmoid(logits)\n",
    "    y_prob = y * prob \n",
    "    def mylog(x):\n",
    "        x = tf.where(x < 1e-20, 1e-20, x)\n",
    "        return tf.math.log(x)\n",
    "    def cross_y_log(y,prob):\n",
    "        ''' return y * log(prob), to avoid 0 * log(0)'''\n",
    "        r = tf.where(y != 0, y * mylog(prob), 0)\n",
    "        return r \n",
    "    part1 = cross_y_log(y,max_with_structure(y_prob,structure)) \n",
    "    part2 = (1-y) * mylog(1 - max_with_structure(prob,structure))\n",
    "    return tf.reduce_mean(-part1 -part2)\n",
    "\n",
    "logits = tf.random.uniform(shape=train.Y.shape, minval=-1, maxval=1)\n",
    "loss_1(train.Y, logits, structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.83531344>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss_2(y_true, logits, strucutre):\n",
    "    cross_logits_y = get_cross_logits_y(y_true)\n",
    "    max_with_structure = get_max_with_structure(structure)\n",
    "\n",
    "    loss1 = y_true * softplus(max_with_structure(cross_logits_y(logits)))\n",
    "    loss2 = (1-y_true) * softplus(max_with_structure(logits)) \n",
    "    loss3 = (1-y_true) * max_with_structure(logits)\n",
    "    return tf.reduce_mean(loss1+loss2+loss3)\n",
    "loss_2(train.Y, logits, structure)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d1df8a9c631c41e95662a04b9faaa5fcedaf5ec92d88d24f4a9901426a87932"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
